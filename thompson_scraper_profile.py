# -*- coding: utf-8 -*-
"""Thompson_scraper_profile.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YrhRlaoD6sEbbD1NxO8Qd382N9s8jb8H
"""

import requests
from bs4 import BeautifulSoup
import json
import csv
import pandas as pd

def scrape_company_info(company_symbols):
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36'}

    company_info_list = []

    for symbol in company_symbols:
        url = f'https://finance.yahoo.com/quote/{symbol}/profile?p={symbol}'
        r = requests.get(url, headers=headers)

        if r.status_code == 200:
            soup = BeautifulSoup(r.text, 'html.parser')
            company_info = {}

            # Scrape company name
            company_info['Company Name'] = soup.find('h3', class_='Fz(m) Mb(10px)').text.strip()

            # Scrape address
            address = soup.find('p', class_='D(ib) W(47.727%) Pend(40px)').text.strip()
            company_info['Address'] = address

            # Scrape sector and industry
            sector = soup.find_all('span', class_='Fw(600)')[0].text.strip()
            industry = soup.find_all('span', class_='Fw(600)')[1].text.strip()
            company_info['Industry'] = industry

            # Scrape full-time employees
            full_time_employees = soup.find_all('span', class_='Fw(600)')[-1].text.strip()
            company_info['Full Time Employees'] = full_time_employees

            # Scrape description
            description = soup.find('p', class_='Mt(15px) Lh(1.6)').text.strip()
            company_info['Description'] = description

            # Scrape executives
            executives = []
            executive_rows = soup.find_all('tr', class_='C($primaryColor) BdB Bdc($seperatorColor) H(36px)')
            for row in executive_rows:
                name = row.find('td', class_='Ta(start)').text.strip()
                title = row.find('td', class_='Ta(start) W(45%)').text.strip()
                executives.append({'Name': name, 'Title': title})
            company_info['Executives'] = executives

            company_info_list.append(company_info)
        else:
            print(f"Profile link not found for {symbol}.")

    return company_info_list

# Company symbols to scrape information for
company_symbols = ['TSLA', 'AAPL', 'GOOG', 'AMZN', 'META', 'INTC']

# Call the function to scrape company information
company_info = scrape_company_info(company_symbols)

# Exporting to JSON
with open('Thompson_stock_holder.json', 'w', encoding='utf-8') as f:
    json.dump(company_info, f, indent=4)

# Exporting to CSV
CSV_FILE_PATH = 'Thompson_stock_holder.csv'
with open(CSV_FILE_PATH, 'w', newline='', encoding='utf-8') as csvfile:
    fieldnames = ['Company Name', 'Address', 'Industry', 'Full Time Employees', 'Description', 'Executives']
    writer = csv.DictWriter(csvfile, fieldnames=fieldnames, extrasaction='ignore')
    writer.writeheader()
    writer.writerows(company_info)

# Exporting to Excel
EXCEL_FILE_PATH = 'Thompson_stock_holder.xlsx'
df = pd.DataFrame(company_info)
df.to_excel(EXCEL_FILE_PATH, index=False)

print("Company information has been exported successfully to JSON, CSV, and Excel files.")

from google.colab import files

# Download Excel file
files.download('Thompson_stock_holder.xlsx')

# Download CSV file
files.download('Thompson_stock_holder.csv')

# Download JSON file
files.download('Thompson_stock_holder.json')