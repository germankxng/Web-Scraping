# -*- coding: utf-8 -*-
"""Thompson_Time_Series_Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ztBo3BBFIm5rNVwXsWgSAl12S_LgrM2n
"""

import yfinance as yf
#Import the Libraries
import math
import pandas_datareader as web
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import Dense, LSTM
import matplotlib.pyplot as plt
import datetime
plt.style.use("fivethirtyeight")

"""Apple Stock Market Analyis"""

# Create Ticker variables
aapl = yf.Ticker("AAPL")
#Set the time range
aapl_hist = aapl.history(start=datetime.datetime(2010, 1, 1),end=datetime.datetime.today())
aapl_hist.head(20)

#Visualization of the Closing price
plt.figure(figsize=(16,8))
plt.title("Closing Price History")
plt.plot(aapl_hist["Close"])
plt.xlabel("Date", fontsize=18)
plt.ylabel("Closing Price USD $", fontsize=18)
plt.show()

#Create a new dataframe with only the Adj Close Column
data = aapl_hist.filter(["Close"])
#Convert the dataframe to a numpy array
dataset = data.values
#Get the number of rows to train the model on
training_data_len = math.ceil( len(dataset) *.8) #This is use to train 80% of the dataset

training_data_len

#Scale the data
scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(dataset)

scaled_data
#Scaling the data means you are actually standardizing your data

#Create the training model for the dataset
#Create the scaled training dataset
train_data = scaled_data[0:training_data_len , :]
#Split the data into x_train & y_train
x_train = []
y_train = []

for i in range(60, len(train_data)):
    x_train.append(train_data[i-60:i, 0])
    y_train.append(train_data[i, 0])
    if i<= 61:
        print(x_train)
        print(y_train)
        print()

# Convert x_train to a numpy array
x_train = np.array(x_train)

# Reshape the data to a 3-dimensional shape
x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))

# Now x_train should have a 3-dimensional shape
print(x_train.shape)

from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.layers import Dense, LSTM
from tensorflow.keras.models import Sequential

#Build the LSTM model
model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape= (x_train.shape[1], 1)))#50 means the no of input neurons
model.add(LSTM(50, return_sequences= False))
model.add(Dense(25))
model.add(Dense(1))# Final output

#Compile the model
model.compile(optimizer="adam", loss="mean_squared_error")

# Create the testing data set
# Create a new array containing scaled values from index 1543 to 2003
test_data = scaled_data[training_data_len - 60:, :]

# Create the data sets x_test and y_test
x_test = []
y_test = dataset[training_data_len:, :]

for i in range(60, len(test_data)):
    x_test.append(test_data[i-60:i, 0])

#Convert the data to a numpy array
x_test = np.array(x_test)#Reshape the data
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1 ))

#Get the model predicted price values
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

# Evaluate the model: Getting the root square error (RMSE)
rmse = np.sqrt(np.mean((predictions - y_test)**2))
rmse

#Plot the data
train = data[:training_data_len]
valid = data[training_data_len:]
valid["Predictions"] = predictions
#Visualize the data
plt.figure(figsize=(16,8))
plt.title("Model")
plt.xlabel("Data", fontsize=18)
plt.ylabel("Close Price USD ($)", fontsize=18)
plt.plot(train["Close"])
plt.plot(valid[["Close", "Predictions"]])
plt.legend(["Train", "Val", "Predictions"], loc="lower right")
plt.show()

"""**Microsoft Stock Market Analyis**"""

plt.style.use("fivethirtyeight")

# Create Ticker variables
msft = yf.Ticker("MSFT")

# Set the time range
msft_hist = msft.history(start=datetime.datetime(2010, 1, 1), end=datetime.datetime.today())
msft_hist.head(20)

# Visualization of the Closing price
plt.figure(figsize=(16,8))
plt.title("Microsoft Closing Price History")
plt.plot(msft_hist["Close"])
plt.xlabel("Date", fontsize=18)
plt.ylabel("Closing Price USD $", fontsize=18)
plt.show()

# Create a new dataframe with only the Adj Close Column
data = msft_hist.filter(["Close"])

# Convert the dataframe to a numpy array
dataset = data.values

# Get the number of rows to train the model on
training_data_len = math.ceil(len(dataset) * .8) # This is used to train 80% of the dataset

# Scale the data
scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(dataset)

# Create the training model for the dataset
# Create the scaled training dataset
train_data = scaled_data[0:training_data_len, :]
# Split the data into x_train & y_train
x_train = []
y_train = []

for i in range(60, len(train_data)):
    x_train.append(train_data[i-60:i, 0])
    y_train.append(train_data[i, 0])
    if i <= 61:
        print(x_train)
        print(y_train)
        print()

# Convert x_train to a numpy array
x_train = np.array(x_train)

# Reshape the data to a 3-dimensional shape
x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))

# Build the LSTM model
model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(x_train.shape[1], 1)))
model.add(LSTM(50, return_sequences=False))
model.add(Dense(25))
model.add(Dense(1))

# Compile the model
model.compile(optimizer="adam", loss="mean_squared_error")

# Create the testing data set
test_data = scaled_data[training_data_len - 60:, :]

# Create the data sets x_test and y_test
x_test = []
y_test = dataset[training_data_len:, :]

for i in range(60, len(test_data)):
    x_test.append(test_data[i-60:i, 0])

# Convert the data to a numpy array
x_test = np.array(x_test)
# Reshape the data
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))

# Get the model predicted price values
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

# Evaluate the model: Getting the root square error (RMSE)
rmse = np.sqrt(np.mean((predictions - y_test)**2))
print("Root Mean Squared Error (RMSE):", rmse)

# Plot the data
train = data[:training_data_len]
valid = data[training_data_len:]
valid["Predictions"] = predictions

# Visualize the data
plt.figure(figsize=(16,8))
plt.title("Microsoft Model")
plt.xlabel("Date", fontsize=18)
plt.ylabel("Close Price USD ($)", fontsize=18)
plt.plot(train["Close"])
plt.plot(valid[["Close", "Predictions"]])
plt.legend(["Train", "Val", "Predictions"], loc="lower right")
plt.show()

"""**Tesla Stock Market Analyis**"""

plt.style.use("fivethirtyeight")

# Create Ticker variables
tsla = yf.Ticker("TSLA")

# Set the time range
tsla_hist = tsla.history(start=datetime.datetime(2010, 1, 1), end=datetime.datetime.today())
tsla_hist.head(20)

# Visualization of the Closing price
plt.figure(figsize=(16,8))
plt.title("Tesla Closing Price History")
plt.plot(tsla_hist["Close"])
plt.xlabel("Date", fontsize=18)
plt.ylabel("Closing Price USD $", fontsize=18)
plt.show()

# Create a new dataframe with only the Close Column
data = tsla_hist.filter(["Close"])

# Convert the dataframe to a numpy array
dataset = data.values

# Get the number of rows to train the model on
training_data_len = math.ceil(len(dataset) * .8) # This is used to train 80% of the dataset

# Scale the data
scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(dataset)

# Create the training model for the dataset
# Create the scaled training dataset
train_data = scaled_data[0:training_data_len, :]
# Split the data into x_train & y_train
x_train = []
y_train = []

for i in range(60, len(train_data)):
    x_train.append(train_data[i-60:i, 0])
    y_train.append(train_data[i, 0])
    if i <= 61:
        print(x_train)
        print(y_train)
        print()

# Convert x_train to a numpy array
x_train = np.array(x_train)

# Reshape the data to a 3-dimensional shape
x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))

# Build the LSTM model
model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(x_train.shape[1], 1)))
model.add(LSTM(50, return_sequences=False))
model.add(Dense(25))
model.add(Dense(1))

# Compile the model
model.compile(optimizer="adam", loss="mean_squared_error")

# Create the data sets x_test and y_test
x_test = []
y_test = dataset[training_data_len:, :]

for i in range(60, len(test_data)):
    x_test.append(test_data[i-60:i, 0])

# Convert the data to a numpy array
x_test = np.array(x_test)
# Reshape the data
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))

# Get the model predicted price values
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

# Trim predictions to match the length of y_test_trimmed
predictions_trimmed = predictions[-len(y_test_trimmed):]

# Evaluate the model: Getting the root square error (RMSE)
rmse = np.sqrt(np.mean((predictions_trimmed - y_test_trimmed)**2))
print("Root Mean Squared Error (RMSE):", rmse)

# Trimming the 'valid' DataFrame to match the length of predictions
valid_trimmed = valid.iloc[:len(predictions)]

# Adding 'Predictions' column to the trimmed 'valid' DataFrame
valid_trimmed['Predictions'] = predictions

# Visualize the data
plt.figure(figsize=(16,8))
plt.title("Tesla Model")
plt.xlabel("Date", fontsize=18)
plt.ylabel("Close Price USD ($)", fontsize=18)
plt.plot(train["Close"])
plt.plot(valid_trimmed[["Close", "Predictions"]])
plt.legend(["Train", "Val", "Predictions"], loc="lower right")
plt.show()

# Trimming the 'valid' DataFrame to match the length of predictions
valid_trimmed = valid.iloc[:len(predictions)]

# Reset the index of predictions array to align with valid_trimmed
predictions_df = pd.DataFrame(predictions, columns=["Predictions"])

# Adding 'Predictions' column to the trimmed 'valid' DataFrame
valid_trimmed.reset_index(drop=True, inplace=True)
predictions_df.reset_index(drop=True, inplace=True)

valid_with_predictions = pd.concat([valid_trimmed, predictions_df], axis=1)

# Visualize the data
plt.figure(figsize=(16,8))
plt.title("Tesla Model")
plt.xlabel("Date", fontsize=18)
plt.ylabel("Close Price USD ($)", fontsize=18)
plt.plot(train["Close"])
plt.plot(valid_with_predictions["Close"])
plt.plot(valid_with_predictions["Predictions"])
plt.legend(["Train", "Val", "Predictions"], loc="lower right")
plt.show()